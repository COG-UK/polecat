#!/usr/bin/env python

import csv
from Bio import SeqIO
import os
import yaml


output_prefix = config["output_prefix"]
##### Configuration #####

if config.get("force"):
    config["force"] = "--forceall "

##### Target rules #####
rule all:
    input:
        os.path.join(config["outdir"],"report", f"{output_prefix}.html")

rule polecat_csv:
    input:
        tree = config["background_tree"],
        metadata = config["background_metadata"]
    output:
        csv = os.path.join(config["outdir"],"clusters.all.csv")
    shell:
        """
        jclusterfunk polecat \
        -i "{input.tree:q}" \
        -m {input.metadata:q} \
        {config[max_age]} \
        {config[max_count]} \
        {config[max_recency]} \
        {config[max_size]} \
        {config[min_size]} \
        {config[min_UK]} \
        {config[optimize_by]} \
        {config[rank_by]} \
        --id-column sequence_name \
        -o "{output.csv}" \
        --ignore-missing 
        """

rule process_clusters:
    input:
        snakefile = os.path.join(workflow.current_basedir,"polecat_pipeline.smk"),
        background_metadata = config["background_metadata"],
        query = rules.polecat_csv.output.csv
    threads: workflow.cores
    params:
        clusterdir = os.path.join(config["outdir"],"cluster_trees")
    output:
        filtered_metadata = os.path.join(config["outdir"],"tip_metadata.csv"),
        yaml = os.path.join(config["tempdir"],"config.yaml")
    run:
        clusters = collections.defaultdict(list)

        with open(input.query, "r") as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                
                tips = row["tips"].split("|")
                for tip in tips:
                    clusters[row["node_number"]].append(tip)

        with open(output.filtered_metadata, "w") as fw:

            with open(input.background_metadata, "r") as f:
                reader = csv.DictReader(f)
                header = reader.fieldnames
                header.append("cluster")

                writer = csv.DictWriter(fw, fieldnames=header,lineterminator='\n')
                writer.writeheader()
                for row in reader:
                    new_row = row
                    c_list = []
                    for c in clusters:
                        tips = clusters[c]
                        
                        if row["sequence_name"] in tips:
                            c_list.append(c)
                    c_string = "|".join(c_list)
                    new_row["cluster"] = c_string

                    writer.writerow(new_row)
        
        config["clusters"] = clusters
        config["clusterdir"] = params.clusterdir
        config["config"] = output.yaml

        with open(output.yaml, 'w') as fw:
            yaml.dump(config, fw)
        if clusters:
            shell("snakemake --nolock --snakefile {input.snakefile:q} "
                                "{config[force]} "
                                "{config[log_string]} "
                                "--directory {config[tempdir]:q} "
                                "--configfile {output.yaml:q} "
                                "--config "
                                "filtered_metadata={output.filtered_metadata:q} "
                                "--cores {workflow.cores}")
        else:
            pass

rule make_report:
    input:
        rules.process_clusters.output.filtered_metadata,
        query = rules.polecat_csv.output.csv
    output:
        report = os.path.join(config["outdir"],"report", f"{output_prefix}.md"),
        yaml = os.path.join(config["tempdir"],"report_config.yaml")
    run:
        config["all_clusters"] = input.query 
        config["config"] = output.yaml

        with open(output.yaml, 'w') as fw:
            yaml.dump(config, fw)
            
        shell("polecat_report.py --config {output.yaml} --report {output.report}")

rule launch_grip:
    input:
        mdfile = os.path.join(config["outdir"],"report", f"{output_prefix}.md")
    output:
        out_file = os.path.join(config["outdir"],"report",f"{output_prefix}.html")
    run:
        shell("grip {input.mdfile:q} --export")
        if config["launch_browser"]:
            for i in range(8000, 8100):
                try:
                    shell("grip {input.mdfile:q} -b {i}")
                    break
                except:
                    print("Trying next port")